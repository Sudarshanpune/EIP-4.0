{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR83To4LStlD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "b514c82d-a788-46e1-e84b-2a51c9ffda22"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import GlobalAveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-z7B0WgSvGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_XJOQ6vS59D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqxblXfCS897",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJFOXnvGTPi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6f5d7526-15bc-4246-e113-e820d38672c7"
      },
      "source": [
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5g89L5wTjG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 40:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 35:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 30:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 25:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AFKP1stTqDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8ZmQ6bZTuCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    y = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YukcXC_7TyxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df73b73b-ce3c-4360-8be6-c0912fb9cf07"
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "  \n",
        "keras.optimizers.RMSprop(lr=lr_schedule(0), rho=0.9)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Learning rate:  0.001\n",
            "Learning rate:  0.001\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 64)           0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy7tWarZT9oS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLT1ey2SVnHA",
        "colab_type": "code",
        "outputId": "25849c72-2077-403c-eb75-33bda4bf8db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 57s 36ms/step - loss: 1.5762 - acc: 0.4836 - val_loss: 1.4219 - val_acc: 0.5598\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.55980, saving model to /content/saved_models/cifar10_ResNet20v1_model.001.h5\n",
            "Epoch 2/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.1841 - acc: 0.6379 - val_loss: 1.3626 - val_acc: 0.5945\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.55980 to 0.59450, saving model to /content/saved_models/cifar10_ResNet20v1_model.002.h5\n",
            "Epoch 3/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.0306 - acc: 0.6979 - val_loss: 1.1947 - val_acc: 0.6439\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.59450 to 0.64390, saving model to /content/saved_models/cifar10_ResNet20v1_model.003.h5\n",
            "Epoch 4/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 0.9402 - acc: 0.7315 - val_loss: 1.0126 - val_acc: 0.7146\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.64390 to 0.71460, saving model to /content/saved_models/cifar10_ResNet20v1_model.004.h5\n",
            "Epoch 5/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.8746 - acc: 0.7555 - val_loss: 0.9324 - val_acc: 0.7336\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.71460 to 0.73360, saving model to /content/saved_models/cifar10_ResNet20v1_model.005.h5\n",
            "Epoch 6/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.8278 - acc: 0.7736 - val_loss: 0.8609 - val_acc: 0.7658\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.73360 to 0.76580, saving model to /content/saved_models/cifar10_ResNet20v1_model.006.h5\n",
            "Epoch 7/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 49s 32ms/step - loss: 0.7930 - acc: 0.7864 - val_loss: 0.9327 - val_acc: 0.7504\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.76580\n",
            "Epoch 8/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.7614 - acc: 0.7982 - val_loss: 1.2311 - val_acc: 0.6916\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.76580\n",
            "Epoch 9/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.7341 - acc: 0.8090 - val_loss: 0.9657 - val_acc: 0.7523\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.76580\n",
            "Epoch 10/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.7193 - acc: 0.8143 - val_loss: 0.7413 - val_acc: 0.8083\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.76580 to 0.80830, saving model to /content/saved_models/cifar10_ResNet20v1_model.010.h5\n",
            "Epoch 11/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 49s 31ms/step - loss: 0.6963 - acc: 0.8220 - val_loss: 0.9283 - val_acc: 0.7584\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80830\n",
            "Epoch 12/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6867 - acc: 0.8270 - val_loss: 1.4384 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80830\n",
            "Epoch 13/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6662 - acc: 0.8357 - val_loss: 1.3546 - val_acc: 0.6897\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80830\n",
            "Epoch 14/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6616 - acc: 0.8366 - val_loss: 0.8333 - val_acc: 0.7796\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80830\n",
            "Epoch 15/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6505 - acc: 0.8432 - val_loss: 0.7465 - val_acc: 0.8148\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.80830 to 0.81480, saving model to /content/saved_models/cifar10_ResNet20v1_model.015.h5\n",
            "Epoch 16/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6399 - acc: 0.8458 - val_loss: 0.7429 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.81480\n",
            "Epoch 17/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6298 - acc: 0.8491 - val_loss: 0.8760 - val_acc: 0.7808\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.81480\n",
            "Epoch 18/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6237 - acc: 0.8525 - val_loss: 0.7144 - val_acc: 0.8336\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.81480 to 0.83360, saving model to /content/saved_models/cifar10_ResNet20v1_model.018.h5\n",
            "Epoch 19/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6204 - acc: 0.8549 - val_loss: 1.0222 - val_acc: 0.7498\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.83360\n",
            "Epoch 20/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6069 - acc: 0.8588 - val_loss: 0.7414 - val_acc: 0.8279\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.83360\n",
            "Epoch 21/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.6029 - acc: 0.8596 - val_loss: 0.6859 - val_acc: 0.8387\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.83360 to 0.83870, saving model to /content/saved_models/cifar10_ResNet20v1_model.021.h5\n",
            "Epoch 22/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5990 - acc: 0.8621 - val_loss: 0.7452 - val_acc: 0.8201\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.83870\n",
            "Epoch 23/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5945 - acc: 0.8632 - val_loss: 0.7126 - val_acc: 0.8278\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.83870\n",
            "Epoch 24/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5871 - acc: 0.8680 - val_loss: 0.9328 - val_acc: 0.7903\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.83870\n",
            "Epoch 25/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5838 - acc: 0.8679 - val_loss: 0.7806 - val_acc: 0.8129\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.83870\n",
            "Epoch 26/50\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.5773 - acc: 0.8709 - val_loss: 0.8407 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.83870\n",
            "Epoch 27/50\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.4815 - acc: 0.9028 - val_loss: 0.5484 - val_acc: 0.8807\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.83870 to 0.88070, saving model to /content/saved_models/cifar10_ResNet20v1_model.027.h5\n",
            "Epoch 28/50\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.4464 - acc: 0.9146 - val_loss: 0.5407 - val_acc: 0.8849\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.88070 to 0.88490, saving model to /content/saved_models/cifar10_ResNet20v1_model.028.h5\n",
            "Epoch 29/50\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.4306 - acc: 0.9187 - val_loss: 0.5327 - val_acc: 0.8871\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.88490 to 0.88710, saving model to /content/saved_models/cifar10_ResNet20v1_model.029.h5\n",
            "Epoch 30/50\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.4184 - acc: 0.9209 - val_loss: 0.5379 - val_acc: 0.8869\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.88710\n",
            "Epoch 31/50\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.4070 - acc: 0.9240 - val_loss: 0.5348 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.88710\n",
            "Epoch 32/50\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.3932 - acc: 0.9271 - val_loss: 0.5119 - val_acc: 0.8931\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.88710 to 0.89310, saving model to /content/saved_models/cifar10_ResNet20v1_model.032.h5\n",
            "Epoch 33/50\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.3917 - acc: 0.9290 - val_loss: 0.5090 - val_acc: 0.8935\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.89310 to 0.89350, saving model to /content/saved_models/cifar10_ResNet20v1_model.033.h5\n",
            "Epoch 34/50\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.3886 - acc: 0.9291 - val_loss: 0.5060 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.89350 to 0.89470, saving model to /content/saved_models/cifar10_ResNet20v1_model.034.h5\n",
            "Epoch 35/50\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.3850 - acc: 0.9298 - val_loss: 0.5054 - val_acc: 0.8941\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.89470\n",
            "Epoch 36/50\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.3829 - acc: 0.9314 - val_loss: 0.5059 - val_acc: 0.8943\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.89470\n",
            "Epoch 37/50\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.3824 - acc: 0.9310 - val_loss: 0.5066 - val_acc: 0.8939\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.89470\n",
            "Epoch 38/50\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.3825 - acc: 0.9307 - val_loss: 0.5060 - val_acc: 0.8942\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.89470\n",
            "Epoch 39/50\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.3833 - acc: 0.9305 - val_loss: 0.5058 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.89470 to 0.89550, saving model to /content/saved_models/cifar10_ResNet20v1_model.039.h5\n",
            "Epoch 40/50\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.3817 - acc: 0.9322 - val_loss: 0.5045 - val_acc: 0.8946\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.89550\n",
            "Epoch 41/50\n",
            "Learning rate:  1e-06\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.3813 - acc: 0.9310 - val_loss: 0.5067 - val_acc: 0.8942\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.89550\n",
            "Epoch 42/50\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.3814 - acc: 0.9318 - val_loss: 0.5064 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.89550\n",
            "Epoch 43/50\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.3800 - acc: 0.9323 - val_loss: 0.5073 - val_acc: 0.8933\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.89550\n",
            "Epoch 44/50\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.3790 - acc: 0.9321 - val_loss: 0.5060 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.89550\n",
            "Epoch 45/50\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.3802 - acc: 0.9322 - val_loss: 0.5033 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.89550\n",
            "Epoch 46/50\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.3818 - acc: 0.9320 - val_loss: 0.5070 - val_acc: 0.8934\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.89550\n",
            "Epoch 47/50\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.3802 - acc: 0.9315 - val_loss: 0.5042 - val_acc: 0.8942\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.89550\n",
            "Epoch 48/50\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 51s 32ms/step - loss: 0.3816 - acc: 0.9332 - val_loss: 0.5055 - val_acc: 0.8944\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.89550\n",
            "Epoch 49/50\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.3838 - acc: 0.9327 - val_loss: 0.5065 - val_acc: 0.8943\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.89550\n",
            "Epoch 50/50\n",
            "Learning rate:  5e-07\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 0.3832 - acc: 0.9309 - val_loss: 0.5039 - val_acc: 0.8947\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.89550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZqIoiTqVqnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f7c1a10f-f776-4df0-ddee-068c31d6783b"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 134us/step\n",
            "Test loss: 0.503861091041565\n",
            "Test accuracy: 0.8947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9CvpBmllfpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import clear_output, Image, display\n",
        "import PIL.Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jraR0DUlgqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3b9f3bd9-7311-47b6-9eda-a6f93b6b68ad"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "mcount = 0\n",
        "misclass = np.empty((100, 32, 32, 3), dtype=np.float32)\n",
        "\n",
        "for i in range(np.shape(x_test)[0]):\n",
        "    out = np.argmax(np.squeeze(model.predict(np.expand_dims(x_test[i], axis=0))))\n",
        "    y = np.argmax(y_test[i])\n",
        "    if out != y:\n",
        "        print(\"Actual: \", y, \"\\tPredicted: \", out, \"\\tImage: \", i)\n",
        "        last_conv_layer = model.get_layer(\"conv2d_21\")\n",
        "        class_output = model.output[:, out]\n",
        "        grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "        iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "        pooled_grads_value, conv_layer_output_value = iterate([np.expand_dims(x_test[i], axis=0)])\n",
        "        for j in range(64):\n",
        "            conv_layer_output_value[:, :, j] *= pooled_grads_value[j]\n",
        "        heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "        heatmap = np.maximum(heatmap, 0)\n",
        "        heatmap /= np.max(heatmap)\n",
        "        heatmap = cv2.resize(heatmap, (32, 32))\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "        superimposed_img = cv2.addWeighted(cv2.resize(x_test[i], (32, 32)), 0.6, heatmap, 0.4, 0,dtype = cv2.CV_32F)\n",
        "        # showarray(cv2.resize(x_test[i], (32, 32)))\n",
        "        # showarray(superimposed_img)\n",
        "        misclass[mcount, :, :, :] = x_test[i]\n",
        "        misclass[mcount+1, :, :, :] = superimposed_img\n",
        "        mcount += 2\n",
        "        if mcount==20:\n",
        "            break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual:  2 \tPredicted:  8 \tImage:  35\n",
            "Actual:  5 \tPredicted:  7 \tImage:  42\n",
            "Actual:  9 \tPredicted:  1 \tImage:  47\n",
            "Actual:  7 \tPredicted:  3 \tImage:  57\n",
            "Actual:  4 \tPredicted:  5 \tImage:  58\n",
            "Actual:  6 \tPredicted:  3 \tImage:  59\n",
            "Actual:  3 \tPredicted:  5 \tImage:  61\n",
            "Actual:  3 \tPredicted:  5 \tImage:  78\n",
            "Actual:  2 \tPredicted:  6 \tImage:  118\n",
            "Actual:  5 \tPredicted:  3 \tImage:  128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xZS57BdllVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fddfc82e-b939-4223-8422-153fe2dfce36"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig=plt.figure(figsize=(128, 128))\n",
        "columns = 4\n",
        "rows = 25\n",
        "for i in range(1, 21):\n",
        "    img = (misclass[i-1] / 255)\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img*255)\n",
        "plt.subplots_adjust(left=0.0, bottom=None, right=0.05, top=None, wspace=0.2, hspace=0)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAATfCAYAAADECRT5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSoQmbiGEEKJEaOIWQgghSsT/AcOVaFZMUJnPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 9216x9216 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}