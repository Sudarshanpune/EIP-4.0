{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIGHTH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "c66ecda9-76ae-45c8-aa96-77b3510768c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[991])\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f04e49ca940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/Q9SPFaGN6OAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "0a733a79-2c15-4af1-e417-971135395b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "25ffa8f8-66c3-4d1d-dd49-ea92cb9b563c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu',bias=False, input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(8, 1, 1,bias=False, activation='relu')) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu'))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu'))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu'))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3,bias=False, activation='relu'))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4,bias=False,))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., use_bias=False)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\", use_bias=False)`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_57 (Conv2D)           (None, 26, 26, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 24, 24, 16)        2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 24, 24, 8)         128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 10, 10, 16)        1152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 8, 8, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 6, 6, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 4, 4, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 1, 1, 10)          2560      \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,624\n",
            "Trainable params: 13,412\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4), use_bias=False)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "32754ed1-6f9e-472e-ad27-233013c6a398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.4157 - acc: 0.9029 - val_loss: 0.0853 - val_acc: 0.9842\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.1759 - acc: 0.9554 - val_loss: 0.0543 - val_acc: 0.9883\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.1382 - acc: 0.9658 - val_loss: 0.0501 - val_acc: 0.9884\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.1163 - acc: 0.9703 - val_loss: 0.0393 - val_acc: 0.9906\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.1016 - acc: 0.9735 - val_loss: 0.0328 - val_acc: 0.9911\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0885 - acc: 0.9770 - val_loss: 0.0323 - val_acc: 0.9918\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0805 - acc: 0.9788 - val_loss: 0.0312 - val_acc: 0.9920\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0746 - acc: 0.9802 - val_loss: 0.0247 - val_acc: 0.9930\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0681 - acc: 0.9806 - val_loss: 0.0291 - val_acc: 0.9926\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0652 - acc: 0.9807 - val_loss: 0.0243 - val_acc: 0.9926\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0611 - acc: 0.9812 - val_loss: 0.0230 - val_acc: 0.9934\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0584 - acc: 0.9830 - val_loss: 0.0299 - val_acc: 0.9920\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0559 - acc: 0.9827 - val_loss: 0.0217 - val_acc: 0.9940\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0535 - acc: 0.9829 - val_loss: 0.0199 - val_acc: 0.9945\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0509 - acc: 0.9837 - val_loss: 0.0203 - val_acc: 0.9936\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0501 - acc: 0.9832 - val_loss: 0.0242 - val_acc: 0.9927\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0471 - acc: 0.9844 - val_loss: 0.0180 - val_acc: 0.9951\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0463 - acc: 0.9846 - val_loss: 0.0213 - val_acc: 0.9946\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0455 - acc: 0.9842 - val_loss: 0.0184 - val_acc: 0.9946\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0423 - acc: 0.9860 - val_loss: 0.0185 - val_acc: 0.9947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f04e49e2f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "f88c9c62-f510-446f-d5bf-7fc16d061200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.018498290636902674, 0.9947]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qDl21ozBnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}